{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4194b9bb",
   "metadata": {},
   "source": [
    "# EDA and Structural Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afadb986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea933d6f",
   "metadata": {},
   "source": [
    "## Making lite version for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b59a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = '../data/raw/lending-club-full.csv'\n",
    "LITE_DATA_PATH = '../data/processed/lending-club-lite.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0ab20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut the dataset to include essential columns only\n",
    "cols_to_keep = [\n",
    "    'loan_amnt', 'term', 'int_rate', 'installment', 'grade', 'sub_grade',\n",
    "    'emp_length', 'home_ownership', 'annual_inc', 'verification_status',\n",
    "    'issue_d', 'loan_status', 'purpose', 'dti', 'earliest_cr_line',\n",
    "    'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc',\n",
    "    'initial_list_status', 'application_type', 'mort_acc', 'pub_rec_bankruptcies'\n",
    "]\n",
    "\n",
    "df = pd.read_csv(RAW_DATA_PATH, usecols=cols_to_keep)\n",
    "\n",
    "print(f'Raw dataset shape: {df.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6537d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Distribution of target variable (count) - {df[\"loan_status\"].value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b703a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['loan_status'].isin(['Fully Paid', 'Charged Off'])]\n",
    "\n",
    "fully_paid = df[df['loan_status'] == 'Fully Paid']\n",
    "charged_off = df[df['loan_status'] == 'Charged Off']\n",
    "\n",
    "df = pd.concat([\n",
    "    fully_paid.sample(n=4000, random_state=42),\n",
    "    charged_off.sample(n=1000, random_state=42)\n",
    "]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f'Dataset shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f77519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the lite dataset\n",
    "os.makedirs(os.path.dirname(LITE_DATA_PATH), exist_ok=True)\n",
    "df.to_csv(LITE_DATA_PATH, index=False)\n",
    "print(f\"Lite dataset saved to {LITE_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54767f5",
   "metadata": {},
   "source": [
    "## Checking the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3e8bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(LITE_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1436fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape of the dataset: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c016089",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Duplicates in the dataset: {df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b348fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ade697",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b83ed9",
   "metadata": {},
   "source": [
    "Columns with missing values\n",
    "\n",
    "`emp_length`: Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years.\n",
    "\n",
    "`mort_acc`: Number of mortgage accounts.\n",
    "\n",
    "`revol_util`: Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.\n",
    "\n",
    "`pub_rec_bankruptcies`: Number of public record bankruptcies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdc7168",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c305923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Distribution of target variable (count) - {df[\"loan_status\"].value_counts()}')\n",
    "print(f'\\nDistribution of target variable (%) - {df[\"loan_status\"].value_counts(normalize=True) * 100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c109e0",
   "metadata": {},
   "source": [
    "Why 80-20? Just to challenge myself but not too extreme as before that has 99-1. This is a part of learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ef8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Negative numbers -> Income: {(df[\"annual_inc\"] < 0).sum()} | Loan Amount: {(df[\"loan_amnt\"] < 0).sum()} | DTI: {(df[\"dti\"] < 0).sum()}')\n",
    "print(f'Impossible values -> High DTI (>100): {(df[\"dti\"] > 100).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd6da8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = df.select_dtypes(include='object').columns\n",
    "\n",
    "print(\"Categories in column:\\n\")\n",
    "for col in obj_cols:\n",
    "    print(col)\n",
    "    print(df[col].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f02634",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[obj_cols].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b8a8f8",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b026dc",
   "metadata": {},
   "source": [
    "What insights to extract:\n",
    "- loan_status vs features\n",
    "- outliers (boxplot for numeric) -> may get capped\n",
    "- distributions (barchart for categorical) -> minor category may get groupped into 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8b6381",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "if 'loan_status' in categorical_cols:\n",
    "    categorical_cols.remove('loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b218a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_numeric = len(numeric_cols)\n",
    "cols_per_row = 4\n",
    "\n",
    "# ceiling division to ensure all columns fits\n",
    "n_rows = (n_numeric + cols_per_row - 1) // cols_per_row\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, cols_per_row, figsize=(18, n_rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(numeric_cols):\n",
    "    axes[idx].boxplot(df[col].dropna())\n",
    "    axes[idx].set_title(f'{col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Value')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "for idx in range(n_numeric, len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6012134",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_categorical = len(categorical_cols)\n",
    "cols_per_row = 3\n",
    "\n",
    "# another ceiling division\n",
    "n_rows = (n_categorical + cols_per_row - 1) // cols_per_row\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, cols_per_row, figsize=(18, n_rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(categorical_cols):\n",
    "    value_counts = df[col].value_counts()\n",
    "    axes[idx].bar(range(len(value_counts)), value_counts.values, color='steelblue')\n",
    "    axes[idx].set_xticks(range(len(value_counts)))\n",
    "    axes[idx].set_xticklabels(value_counts.index, rotation=45, ha='right')\n",
    "    axes[idx].set_title(f'{col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Count')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "for idx in range(n_categorical, len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2d7419",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'Fully Paid': '#2ecc71', 'Charged Off': '#e74c3c'}\n",
    "statuses = ['Fully Paid', 'Charged Off']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_numeric = len(numeric_cols)\n",
    "cols_per_row = 4\n",
    "\n",
    "n_rows = (n_numeric + cols_per_row - 1) // cols_per_row\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, cols_per_row, figsize=(20, n_rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(numeric_cols):\n",
    "    data_to_plot = [df[df['loan_status'] == status][col].dropna() for status in statuses]\n",
    "    bp = axes[idx].boxplot(data_to_plot, tick_labels=statuses, patch_artist=True)\n",
    "    \n",
    "    for patch, status in zip(bp['boxes'], statuses):\n",
    "        patch.set_facecolor(colors[status])\n",
    "        patch.set_alpha(0.7)\n",
    "        \n",
    "    axes[idx].set_title(f'{col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Value')\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for idx in range(n_numeric, len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f274c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_categorical = len(categorical_cols)\n",
    "cols_per_row = 3\n",
    "\n",
    "n_rows = (n_categorical + cols_per_row - 1) // cols_per_row\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, cols_per_row, figsize=(20, n_rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(categorical_cols):\n",
    "    cross_tab = pd.crosstab(df[col], df['loan_status'])\n",
    "    cross_tab.plot(kind='bar', ax=axes[idx], color=[colors['Fully Paid'], colors['Charged Off']], alpha=0.8)\n",
    "    \n",
    "    axes[idx].set_title(f'{col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Count')\n",
    "    axes[idx].set_xlabel('')\n",
    "    axes[idx].legend(title='Loan Status', loc='upper right')\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "for idx in range(n_categorical, len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327d6ab9",
   "metadata": {},
   "source": [
    "## Further Analysis: Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8590e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cols = ['emp_length', 'mort_acc', 'revol_util', 'pub_rec_bankruptcies']\n",
    "n = len(df)\n",
    "\n",
    "for c in missing_cols:\n",
    "    m = df[c].isna().sum()\n",
    "    \n",
    "    print(f'\\n=== {c} ===')\n",
    "    print(f'Missing: {m} / {n} ({m/n:.2%})')\n",
    "    print(df[c].describe(include='all'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5e24f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in missing_cols:\n",
    "    miss_rate_by_status = df.groupby('loan_status')[c].apply(lambda s: s.isna().mean()).sort_values(ascending=False)\n",
    "    print(f'\\n=== Missing rate by loan_status {c} ===')\n",
    "    print(miss_rate_by_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e1841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_nums = ['loan_amnt', 'int_rate', 'annual_inc']\n",
    "\n",
    "for c in missing_cols:\n",
    "    flag = df[c].isna()\n",
    "    \n",
    "    print(f'\\n=== {c}: compare w/ key numerics ===')\n",
    "    \n",
    "    for x in key_nums:\n",
    "        if x not in df.columns:\n",
    "            continue\n",
    "        g_missing = df.loc[flag, x].dropna()\n",
    "        g_present = df.loc[~flag, x].dropna()\n",
    "        \n",
    "        print(f'{x}: missing_mean={g_missing.mean():.3f} | present_mean={g_present.mean():.3f} | n_missing={len(g_missing)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db60128",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['emp_length'].isna(), ['loan_status','grade','sub_grade']].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_cols = ['total_acc','open_acc']\n",
    "df.loc[df['mort_acc'].isna(), credit_cols].describe()\n",
    "df.loc[~df['mort_acc'].isna(), credit_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7136ee",
   "metadata": {},
   "source": [
    "## Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9601978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store original shape for comparison\n",
    "original_shape = df.shape[0]\n",
    "\n",
    "# Create a copy for cleaning\n",
    "df_cleaned = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd52a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values (row-independent operations)\n",
    "print(\"Before cleaning:\")\n",
    "print(\"=\"*25)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Missing values:\\n{df.isnull().sum()[df.isnull().sum() > 0]}\\n\")\n",
    "\n",
    "df_cleaned = df_cleaned.dropna(subset=['revol_util', 'pub_rec_bankruptcies'])\n",
    "\n",
    "df_cleaned['mort_acc_missing'] = df_cleaned['mort_acc'].isna().astype(int)\n",
    "df_cleaned['emp_length_missing'] = df_cleaned['emp_length'].isna().astype(int)\n",
    "\n",
    "print(\"After handling missing values:\")\n",
    "print(\"=\"*25)\n",
    "print(f\"Shape: {df_cleaned.shape}\")\n",
    "print(f\"Missing values: {df_cleaned.isnull().sum().sum()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8daee4",
   "metadata": {},
   "source": [
    "### Convert datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7119bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the text to actual Datetime objects\n",
    "# format='%b-%Y' tells Python that \"Mar-2003\" is Month-Year\n",
    "df_cleaned['earliest_cr_line'] = pd.to_datetime(df_cleaned['earliest_cr_line'], format='%b-%Y')\n",
    "df_cleaned['issue_d'] = pd.to_datetime(df_cleaned['issue_d'], format='%b-%Y')\n",
    "\n",
    "# Pick a \"Reference Date\"\n",
    "# Since this is historical data, we shouldn't use \"today\" (2026).\n",
    "# We should use a date relevant to the dataset, like 2020 or the max date in the data.\n",
    "# Let's assume the analysis is happening on Dec 31, 2020.\n",
    "reference_date = pd.to_datetime('2018-12-31')\n",
    "\n",
    "# Calculate the difference (Days -> Years)\n",
    "# We divide by 365.25 to account for leap years\n",
    "df_cleaned['credit_history_years'] = (reference_date - df_cleaned['earliest_cr_line']).dt.days / 365.25\n",
    "df_cleaned['issue_years'] = (reference_date - df_cleaned['issue_d']).dt.days / 365.25\n",
    "\n",
    "# Check the results\n",
    "print(df_cleaned[['earliest_cr_line', 'credit_history_years']].head())\n",
    "print(df_cleaned[['issue_d', 'issue_years']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8247b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original date column because the model can't handle it\n",
    "df_cleaned = df_cleaned.drop(columns=['earliest_cr_line', 'issue_d'])\n",
    "\n",
    "# Verify it's gone\n",
    "print(df_cleaned.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8450ef",
   "metadata": {},
   "source": [
    "### Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b1f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataset\n",
    "CLEANED_DATA_PATH = '../data/processed/lending-club-cleaned.csv'\n",
    "\n",
    "df_cleaned.reset_index(drop=True, inplace=True)\n",
    "df_cleaned.to_csv(CLEANED_DATA_PATH, index=False)\n",
    "\n",
    "# Calculate actual rows removed\n",
    "rows_removed = original_shape - df_cleaned.shape[0]\n",
    "rows_removed_pct = (rows_removed / original_shape) * 100\n",
    "\n",
    "print(\"CLEANING SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Original dataset shape: {original_shape}\")\n",
    "print(f\"Final dataset shape: {df_cleaned.shape[0]}\")\n",
    "print(f\"Rows removed: {rows_removed} ({rows_removed_pct:.2f}%)\")\n",
    "print(f\"\\nCleaned dataset saved to: {CLEANED_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e311b716",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
